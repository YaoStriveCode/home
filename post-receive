#!/usr/bin/python

import gzip
import os
import shlex
import shutil
from subprocess import CalledProcessError, list2cmdline, PIPE, Popen
import sys

puburl = 'http://www.wunjo.org/~jcorbin'
pubdir = '~/public_html'
pubdir = os.path.expanduser(pubdir)

showindex = False

VerboseRun = False
def run(cmd, wait=True, ok_retcodes=(0,), **kwargs):
    if isinstance(cmd, unicode):
        cmd = cmd.encode('ascii')
    if isinstance(cmd, str):
        cmdstr = cmd
        cmd = shlex.split(cmd)
    else:
        cmdstr = list2cmdline(cmd)
    if VerboseRun:
        print '+', cmdstr
        sys.stdout.flush()
    p = Popen(cmd, **kwargs)
    p.cmdstr = cmdstr
    p.cmd = cmd
    if wait:
        retcode = p.wait()
        if retcode not in ok_retcodes:
            raise CalledProcessError(retcode, p.cmdstr)
    return p

run_output = lambda cmd, **kwargs: run(cmd, stdout=PIPE, **kwargs).stdout
run_line   = lambda cmd, **kwargs: run_output(cmd, **kwargs).readline().strip()

def revs(*revs):
    if not len(revs): return None
    cmd = ('git', 'rev-parse') + revs
    rs = run_output(cmd)
    if len(revs) == 1:
        return rs.readline().strip()
    else:
        return (rev.strip() for rev in rs)

def shortrevs(*rs):
    for rev in revs(*rs):
        yield rev[:7]

def path_sha(rev, path):
    if rev == '0' * 40: return None
    try:
        return revs(rev + ':' + path)
    except CalledProcessError:
        return None

def update_file(old, new, repopath, target):
    oldob = path_sha(old, repopath)
    newob = path_sha(new, repopath)
    if oldob == newob: return False
    if newob is None:
        os.unlink(target)
        return True
    with open(target, 'w') as f:
        show = run_output(('git', 'show', new + ':' + repopath))
        shutil.copyfileobj(show, f)
        print 'updated', target
        sys.stdout.flush()
        return True

def read_watchers(ref, name):
    for line in run_output('git show ' + ref + ':' + name  + '-watchers'):
        yield line.strip()

def read_checkouts(meta_ref):
    path = meta_ref + ':checkouts'
    for i, line in enumerate(run_output(('git', 'show', path))):
        line = line.strip()
        if not line: continue
        try:
            repopath, target = line.split(None, 1)
        except ValueError:
            print >>sys.stderr, \
                'bogus checkouts:{0}: {1}'.format(i+1, line)
        target = os.path.expanduser(target)
        target = os.path.realpath(target)
        yield repopath, target

import cgi
def html_doc(title, contents):
    s = "<!doctype html>\n"
    s += "<html>"
    s += "<head><title>" + cgi.escape(title) + "</title></head>"
    s += "<body>"
    s += contents
    s += "</body></html>\n"
    return s

def index_contents(title, packdir):
    s = "<ul>"
    for ent in os.listdir(packdir):
        if not ent.endswith('.sh.gz'): continue
        s += "<li><a href=\"{0}\">{0}</a></li>".format(ent)
    s += "</ul>"
    return html_doc(title, s)

from bisect import bisect

def make_pack(meta_ref, remote, branch, rev):
    packdir = os.path.join(pubdir, remote)
    packdirurl = puburl + '/' + remote
    ship_ref = 'refs/heads/' + branch
    pack_refspec = rev + ':' + ship_ref

    # TODO: run ack once it's updated
    # run(os.path.join(os.getcwd(), 'ack'))

    if not os.path.exists(packdir):
        os.makedirs(packdir)

    thepack = run_line(('git', 'shell-pack', 'make', remote, pack_refspec))
    packid = thepack.rpartition('-')[2].partition('.')[0]

    pack_history = []
    if os.path.exists('pack_history'):
        with open('pack_history', 'r') as f:
            pack_history = [line.strip().split(None, 1) for line in f]

    packids, refs = [], []
    if pack_history:
        packids, refs = zip(*pack_history)
        packids = list(packids)
        refs = list(refs)
    i = bisect(packids, packid)
    packids.insert(i, packid)
    refs.insert(i, remote + ' ' + pack_refspec)
    pack_history = zip(packids, refs)
    del i, packids, refs

    with open('pack_history', 'w') as f:
        f.writelines(' '.join(h)+'\n' for h in pack_history)

    pubpack = os.path.join(packdir, thepack) + '.gz'
    with open(thepack, 'r') as src, \
         gzip.GzipFile(pubpack, 'w') as dst:
        shutil.copyfileobj(src, dst)
    os.unlink(thepack)
    thepack += '.gz'

    # TODO: old pack cleanup

    desc = open('description', 'r').readline().strip()
    title = '{0}: {1} shell-pack staging'.format(desc, remote)
    with open(os.path.join(packdir, 'index.html'), 'w') as f:
        if showindex:
            f.write(index_contents(title, packdir))
        else:
            f.write(html_doc(title, ''))

    watchers = list(read_watchers(meta_ref, remote))
    if watchers:
        # TODO: use python module
        with open('description') as f:
            desc = f.readline().strip()
        subject = '{0}: {1} available'.format(desc, thepack)
        packurl = packdirurl + '/' + thepack
        cmd = ['mail', '--subject', subject]
        for watcher in watchers:
            cmd += ['--to', watcher]
        mail = run(cmd, wait=False, stdin=PIPE)
        mail.stdin.write(packurl + '\n')
        mail.stdin.close()
        mail.wait()

if __name__ == '__main__':
    myself = os.path.realpath(sys.argv[0])
    self_files = (
        myself,
    )

    import optparse
    parser = optparse.OptionParser()
    parser.add_option('--dejavu', action='store_true', default=False)
    parser.add_option('--updated-self', action='append', default=[])
    opts, args = parser.parse_args()
    updated_self = set(opts.updated_self)

    def upgrade_self(old_rev, new_rev):
        upgraded = False
        for repopath, target in read_checkouts(meta_ref):
            if target in updated_self or target not in self_files: continue
            if update_file(old_rev, new_rev, repopath, target):
                updated_self.add(target)
                upgraded = True
        if not upgraded: return

        r, w = os.pipe()
        os.write(w, ''.join('{0} {1} {2}\n'.format(old, new, ref)
            for ref, (old, new) in updates.iteritems()))
        os.close(w)
        os.dup2(r, sys.stdin.fileno())
        os.close(r)
        sys.stdout.flush()
        args = [sys.argv[0]]
        for path in sorted(updated_self):
            args += ['--updated-self', path]
        if VerboseRun:
            print '+', '(execv)', myself, ' '.join(args)
        else:
            print 'reexecing', myself
        sys.stdout.flush()
        os.execv(myself, args)

    updates = [line.strip().split(None, 2) for line in sys.stdin]
    updates = dict((refname, (old, new)) for old, new, refname in updates)

    meta_ref = 'refs/heads/meta'

    if meta_ref in updates:
        old_rev, new_rev = updates[meta_ref]
        upgrade_self(old_rev, new_rev)
        for repopath, target in read_checkouts(meta_ref):
            if target in self_files: continue
            update_file(old_rev, new_rev, repopath, target)

    run('git repack -Ad')
    run('git gc')

    import re
    for_ref = re.compile(r'refs/remotes/for/([^/]+)/([^/]+)$')
    # TODO: support multiple branches per pack
    for ref, (old_rev, new_rev) in updates.iteritems():
        match = for_ref.match(ref)
        if not match: continue
        remote, branch = match.groups()

        if new_rev == '0' * 40:
            tracking_ref = 'refs/remotes/{0}/{1}'.format(remote, branch)
            tracking_ref = 'refs/remotes/' + remote + '/' + branch
            try:
                run(('git', 'show-ref', tracking_ref, '--verify', '--quiet'))
            except CalledProcessError:
                pass
            else:
                run(('git', 'update-ref', '-d', tracking_ref))
            packdir = os.path.join(pubdir, remote)
            if os.path.exists(packdir):
                shutil.rmtree(packdir)

        else:
            make_pack(meta_ref, remote, branch, new_rev)
